{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jgs-rnn.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6YYO-kOnoxLI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# !pip install textgenrnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKH-94Yroqzw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "0ef2ab01-7553-45bb-ae4e-9a3663b68a64",
        "executionInfo": {
          "status": "error",
          "timestamp": 1531989789370,
          "user_tz": 240,
          "elapsed": 296,
          "user": {
            "displayName": "Luming Hao",
            "photoUrl": "//lh5.googleusercontent.com/-2JGZDMtGqMo/AAAAAAAAAAI/AAAAAAAAAbM/npdYuGIdCN0/s50-c-k-no/photo.jpg",
            "userId": "107166296863023479912"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "import json "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-58cc367d82eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtextgenrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtextgenrnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textgenrnn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "urc2kn7AkpCB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce9a5f6f-b6f0-44ec-bc33-84b2371d22f4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531986551845,
          "user_tz": 240,
          "elapsed": 1030,
          "user": {
            "displayName": "Luming Hao",
            "photoUrl": "//lh5.googleusercontent.com/-2JGZDMtGqMo/AAAAAAAAAAI/AAAAAAAAAbM/npdYuGIdCN0/s50-c-k-no/photo.jpg",
            "userId": "107166296863023479912"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# double checking that google isn't lying\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hldgPnWAlodN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2528ea31-7485-4e54-efdd-311ee4c0a9f0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531971043261,
          "user_tz": 240,
          "elapsed": 18864,
          "user": {
            "displayName": "Luming Hao",
            "photoUrl": "//lh5.googleusercontent.com/-2JGZDMtGqMo/AAAAAAAAAAI/AAAAAAAAAbM/npdYuGIdCN0/s50-c-k-no/photo.jpg",
            "userId": "107166296863023479912"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "aquatic_file = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-210c9859-718e-467d-be0b-38022b33f6d5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-210c9859-718e-467d-be0b-38022b33f6d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving aquatic.json to aquatic.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YZBKKH8LpDMh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "aquatic_json = json.loads(aquatic_file[\"aquatic.json\"])\n",
        "all_normalized = [\"\\n\".join(piece[\"normalized\"]) for piece in aquatic_json[\"pieces\"]]\n",
        "\n",
        "# making a csv bc that's what textgenrnn likes (at least for multiline-string texts)\n",
        "with open(\"aquatic.csv\", \"w\") as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    for normalized in all_normalized:\n",
        "        csvwriter.writerow([normalized])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9O0FXJDkmUsA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b78a1186-c09b-4022-d639-72c49a15c0fa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531971203777,
          "user_tz": 240,
          "elapsed": 348,
          "user": {
            "displayName": "Luming Hao",
            "photoUrl": "//lh5.googleusercontent.com/-2JGZDMtGqMo/AAAAAAAAAAI/AAAAAAAAAbM/npdYuGIdCN0/s50-c-k-no/photo.jpg",
            "userId": "107166296863023479912"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(random.choice(all_normalized))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o           .'`/\n",
            "    '      /  (\n",
            "  O    .-'` ` `'-._      .')\n",
            "     _/ (o)        '.  .' /\n",
            "     )       )))     ><  <\n",
            "     `\\  |_\\      _.'  '. \\\n",
            "       '-._  _ .-'       '.)\n",
            "           `\\__\\\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f8eO0iyJwk6D",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "textgen = textgenrnn(name=\"aquatic\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KoG9ZbcxmjI-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3562
        },
        "outputId": "59cfb5af-0cbd-4ec5-f0ca-73f13d7e8123",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531987102914,
          "user_tz": 240,
          "elapsed": 324157,
          "user": {
            "displayName": "Luming Hao",
            "photoUrl": "//lh5.googleusercontent.com/-2JGZDMtGqMo/AAAAAAAAAAI/AAAAAAAAAbM/npdYuGIdCN0/s50-c-k-no/photo.jpg",
            "userId": "107166296863023479912"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 64\n",
        "\n",
        "# textgen.load(\"aquatic_weights.hdf5\") \n",
        "textgen.train_from_file(\n",
        "    \"aquatic.csv\", \n",
        "    header=False, \n",
        "    is_csv=True, \n",
        "    gen_epochs=n_epochs,\n",
        "    new_model=True,\n",
        "    num_epochs=n_epochs\n",
        ")\n",
        "textgen.save()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61 texts collected.\n",
            "Training new model w/ 2-layer, 128-cell LSTMs\n",
            "Training on 19,425 character sequences.\n",
            "Epoch 1/64\n",
            "151/151 [==============================] - 7s 49ms/step - loss: 1.8858\n",
            "Epoch 2/64\n",
            "151/151 [==============================] - 6s 38ms/step - loss: 1.6281\n",
            "Epoch 3/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 1.4330\n",
            "Epoch 4/64\n",
            "151/151 [==============================] - 5s 36ms/step - loss: 1.3667\n",
            "Epoch 5/64\n",
            "  5/151 [..............................] - ETA: 5s - loss: 1.3471"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 5s 36ms/step - loss: 1.3197\n",
            "Epoch 6/64\n",
            "151/151 [==============================] - 5s 36ms/step - loss: 1.2823\n",
            "Epoch 7/64\n",
            "151/151 [==============================] - 5s 36ms/step - loss: 1.2519\n",
            "Epoch 8/64\n",
            "151/151 [==============================] - 5s 36ms/step - loss: 1.2119\n",
            "Epoch 9/64\n",
            "151/151 [==============================] - 5s 36ms/step - loss: 1.1694\n",
            "Epoch 10/64\n",
            " 39/151 [======>.......................] - ETA: 4s - loss: 1.1259"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 5s 36ms/step - loss: 1.1307\n",
            "Epoch 11/64\n",
            "151/151 [==============================] - 5s 36ms/step - loss: 1.0792\n",
            "Epoch 12/64\n",
            "151/151 [==============================] - 6s 37ms/step - loss: 1.0313\n",
            "Epoch 13/64\n",
            "151/151 [==============================] - 6s 42ms/step - loss: 0.9807\n",
            "Epoch 14/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.9330\n",
            "Epoch 15/64\n",
            "  5/151 [..............................] - ETA: 7s - loss: 0.7905"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 39ms/step - loss: 0.8857\n",
            "Epoch 16/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.8321\n",
            "Epoch 17/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.7922\n",
            "Epoch 18/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.7364\n",
            "Epoch 19/64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 40ms/step - loss: 0.6897\n",
            "Epoch 20/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.6471\n",
            "Epoch 21/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.6083\n",
            "Epoch 22/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.5678\n",
            "Epoch 23/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.5301\n",
            "Epoch 24/64\n",
            " 18/151 [==>...........................] - ETA: 5s - loss: 0.4555"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 39ms/step - loss: 0.4941\n",
            "Epoch 25/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.4688\n",
            "Epoch 26/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.4329\n",
            "Epoch 27/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.4005\n",
            "Epoch 28/64\n",
            "148/151 [============================>.] - ETA: 0s - loss: 0.3821"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 40ms/step - loss: 0.3835\n",
            "Epoch 29/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.3580\n",
            "Epoch 30/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.3341\n",
            "Epoch 31/64\n",
            "151/151 [==============================] - 6s 41ms/step - loss: 0.3155\n",
            "Epoch 32/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.2945\n",
            "Epoch 33/64\n",
            " 18/151 [==>...........................] - ETA: 5s - loss: 0.2244"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 40ms/step - loss: 0.2710\n",
            "Epoch 34/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.2623\n",
            "Epoch 35/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.2489\n",
            "Epoch 36/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.2318\n",
            "Epoch 37/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.2193\n",
            "Epoch 38/64\n",
            " 10/151 [>.............................]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 40ms/step - loss: 0.2052\n",
            "Epoch 39/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.1958\n",
            "Epoch 40/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.1803\n",
            "Epoch 41/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.1765\n",
            "Epoch 42/64\n",
            "150/151 [============================>.] - ETA: 0s - loss: 0.1642"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151/151 [==============================] - 6s 39ms/step - loss: 0.1640\n",
            "Epoch 43/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.1553\n",
            "Epoch 44/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.1442\n",
            "Epoch 45/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.1365\n",
            "Epoch 46/64\n",
            " 92/151 [=================>............] - ETA: 2s - loss: 0.1253"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 39ms/step - loss: 0.1344\n",
            "Epoch 47/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.1231\n",
            "Epoch 48/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.1135\n",
            "Epoch 49/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.1094\n",
            "Epoch 50/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.1035\n",
            "Epoch 51/64\n",
            " 10/151 [>.............................] - ETA: 5s - loss: 0.0805"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 39ms/step - loss: 0.0960\n",
            "Epoch 52/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.0919\n",
            "Epoch 53/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.0885\n",
            "Epoch 54/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.0813\n",
            "Epoch 55/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.0761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 56/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.0718\n",
            "Epoch 57/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.0673\n",
            "Epoch 58/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.0632\n",
            "Epoch 59/64\n",
            "151/151 [==============================] - 6s 40ms/step - loss: 0.0601\n",
            "Epoch 60/64\n",
            "150/151 [============================>.] - ETA: 0s - loss: 0.0563"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151/151 [==============================] - 6s 38ms/step - loss: 0.0561\n",
            "Epoch 61/64\n",
            "151/151 [==============================] - 6s 37ms/step - loss: 0.0523\n",
            "Epoch 62/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.0500\n",
            "Epoch 63/64\n",
            "151/151 [==============================] - 6s 39ms/step - loss: 0.0475\n",
            "Epoch 64/64\n",
            "102/151 [===================>..........] - ETA: 1s - loss: 0.0454"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "151/151 [==============================] - 6s 39ms/step - loss: 0.0454\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "                                    _H_\n",
            "                                   /___\\\n",
            "                                   \\888/\n",
            "~^~~~~~~~~~^^^^^^^^^^^^^~~^~^^^^^^~^~U~^~^^^^^~~~~~^^^^^^^^^^^^^~~^~^^^^^^~^~^~^~^^^^^~~~~~^^^^^^^^^^^^^~~^~^^^^^^~^~^~^~^^^^^~~~~~^^^^^^^^^^^^^~~^~^^^^^^~^~^~^~^^^^^~~~~~^^^^^\n",
            "\n",
            "                                    _H_\n",
            "                                   /___\\\n",
            "                                   \\888/\n",
            "~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^U\n",
            "\n",
            "                                    _H_\n",
            "                                   /___\\\n",
            "                                   \\888/\n",
            "~^~^~~~~~~~^~~^^^^^^^^^^^^^^~^^^~^~^~U~^~^~^^~~~~~~^~~^^^^~^\n",
            "                              ~\n",
            "                                    ||  |\n",
            "               \\                 \\\n",
            "      \n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "                                    `\\`\\`----.,_\n",
            "              .' \\           |            ___\n",
            "                 /',             \\\n",
            "                   \\/        `\n",
            "               '-.,\\\\_               .-`              .'\n",
            "               \\__/           \\`         (       (  \n",
            "                      ,/.. \n",
            "\n",
            "                                    _H_\n",
            "                                   /___\\\n",
            "                                   \\888/\n",
            "~^~~^~~^~~~^^^^^~~~^~^^^~~~^~^^~^~~~~U~^~^~~~~~^~~~^^^^\n",
            "                                    |\n",
            "  |                                   \\\n",
            "                                          \n",
            "\n",
            "                                    _H_\n",
            "                                   /___\\\n",
            "                                   \\888/\n",
            "~^~~^^~^~~~^~~~~^~^^^~^~~~^~~^^^~~~~~U~^~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "     _.---._\n",
            " .:\":_'-.-``_ '.-'\n",
            "|       .'    |\n",
            "  /`._    :::\\\\\\\n",
            "        /\n",
            "\n",
            "          _.-''|''-._\n",
            "    .-'                   `'-:::`\n",
            "                 (       )      `'-:\n",
            "           '-._.'      .'        / o ;\n",
            "     `\\   \\       | /\n",
            "              \\/\n",
            "\n",
            "                     (\\.-.  _\n",
            "          __..        '._   (\n",
            "                   -._           <) `\n",
            "      `\\  |        `.           ((   )   )\n",
            "     ^ u^     u^ u  ^u^\\\n",
            " |    ~~   |`\"-..\\\n",
            "    (   o )       )  )              .'   `'\n",
            "     '                  .-__                     |\n",
            "   _.-'           \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CwvIf4Vw165u",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "results = textgen.generate(n=100, temperature=0.8, return_as_list=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xJfd0lkF6Ys",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v8zgb_X5F1tV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i, result in enumerate(results):\n",
        "  open(\"./results/{0}.txt\".format(i), \"w\").write(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-kw9E0_NGLZp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1754
        },
        "outputId": "4fbbaddd-b4b5-49ee-d8e4-1fd75bb5c10d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531987776554,
          "user_tz": 240,
          "elapsed": 3018,
          "user": {
            "displayName": "Luming Hao",
            "photoUrl": "//lh5.googleusercontent.com/-2JGZDMtGqMo/AAAAAAAAAAI/AAAAAAAAAbM/npdYuGIdCN0/s50-c-k-no/photo.jpg",
            "userId": "107166296863023479912"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!zip -r results.zip ./results/*"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: results/0.txt (deflated 77%)\r\n",
            "  adding: results/1.txt (deflated 58%)\r\n",
            "  adding: results/10.txt (deflated 70%)\r\n",
            "  adding: results/11.txt (deflated 71%)\r\n",
            "  adding: results/12.txt (deflated 56%)\r\n",
            "  adding: results/13.txt (deflated 60%)\r\n",
            "  adding: results/14.txt (deflated 75%)\r\n",
            "  adding: results/15.txt (deflated 55%)\r\n",
            "  adding: results/16.txt (deflated 58%)\r\n",
            "  adding: results/17.txt (deflated 65%)\r\n",
            "  adding: results/18.txt (deflated 64%)\r\n",
            "  adding: results/19.txt (deflated 65%)\r\n",
            "  adding: results/2.txt (deflated 64%)\r\n",
            "  adding: results/20.txt (deflated 75%)\r\n",
            "  adding: results/21.txt (deflated 70%)\r\n",
            "  adding: results/22.txt (deflated 76%)\r\n",
            "  adding: results/23.txt (deflated 52%)\r\n",
            "  adding: results/24.txt (deflated 77%)\r\n",
            "  adding: results/25.txt (deflated 75%)\r\n",
            "  adding: results/26.txt (deflated 76%)\r\n",
            "  adding: results/27.txt (deflated 51%)\r\n",
            "  adding: results/28.txt (deflated 80%)\r\n",
            "  adding: results/29.txt (deflated 62%)\r\n",
            "  adding: results/3.txt (deflated 78%)\r\n",
            "  adding: results/30.txt (deflated 78%)\r\n",
            "  adding: results/31.txt (deflated 66%)\r\n",
            "  adding: results/32.txt (deflated 65%)\r\n",
            "  adding: results/33.txt (deflated 57%)\r\n",
            "  adding: results/34.txt (deflated 61%)\r\n",
            "  adding: results/35.txt (deflated 67%)\r\n",
            "  adding: results/36.txt (deflated 55%)\r\n",
            "  adding: results/37.txt (deflated 61%)\r\n",
            "  adding: results/38.txt (deflated 81%)\r\n",
            "  adding: results/39.txt (deflated 62%)\r\n",
            "  adding: results/4.txt (deflated 73%)\r\n",
            "  adding: results/40.txt (deflated 62%)\r\n",
            "  adding: results/41.txt (deflated 66%)\r\n",
            "  adding: results/42.txt (deflated 69%)\r\n",
            "  adding: results/43.txt (deflated 47%)\r\n",
            "  adding: results/44.txt (deflated 70%)\r\n",
            "  adding: results/45.txt (deflated 55%)\r\n",
            "  adding: results/46.txt (deflated 67%)\r\n",
            "  adding: results/47.txt (deflated 74%)\r\n",
            "  adding: results/48.txt (deflated 92%)\r\n",
            "  adding: results/49.txt (deflated 52%)\r\n",
            "  adding: results/5.txt (deflated 65%)\r\n",
            "  adding: results/50.txt (deflated 54%)\r\n",
            "  adding: results/51.txt (deflated 64%)\r\n",
            "  adding: results/52.txt (deflated 81%)\r\n",
            "  adding: results/53.txt (deflated 54%)\r\n",
            "  adding: results/54.txt (deflated 24%)\r\n",
            "  adding: results/55.txt (deflated 72%)\r\n",
            "  adding: results/56.txt (deflated 75%)\r\n",
            "  adding: results/57.txt (deflated 64%)\r\n",
            "  adding: results/58.txt (deflated 55%)\r\n",
            "  adding: results/59.txt (deflated 61%)\r\n",
            "  adding: results/6.txt (deflated 76%)\r\n",
            "  adding: results/60.txt (deflated 86%)\r\n",
            "  adding: results/61.txt (deflated 83%)\r\n",
            "  adding: results/62.txt (deflated 75%)\r\n",
            "  adding: results/63.txt (deflated 77%)\r\n",
            "  adding: results/64.txt (deflated 69%)\r\n",
            "  adding: results/65.txt (deflated 77%)\r\n",
            "  adding: results/66.txt (deflated 32%)\r\n",
            "  adding: results/67.txt (deflated 61%)\r\n",
            "  adding: results/68.txt (deflated 84%)\r\n",
            "  adding: results/69.txt (deflated 55%)\r\n",
            "  adding: results/7.txt (deflated 56%)\r\n",
            "  adding: results/70.txt (deflated 65%)\r\n",
            "  adding: results/71.txt (deflated 78%)\r\n",
            "  adding: results/72.txt (deflated 63%)\r\n",
            "  adding: results/73.txt (deflated 60%)\r\n",
            "  adding: results/74.txt (deflated 49%)\r\n",
            "  adding: results/75.txt (deflated 66%)\r\n",
            "  adding: results/76.txt (deflated 69%)\r\n",
            "  adding: results/77.txt (deflated 78%)\r\n",
            "  adding: results/78.txt (deflated 74%)\r\n",
            "  adding: results/79.txt (deflated 79%)\r\n",
            "  adding: results/8.txt (deflated 81%)\r\n",
            "  adding: results/80.txt (deflated 61%)\r\n",
            "  adding: results/81.txt (deflated 46%)\r\n",
            "  adding: results/82.txt (deflated 56%)\r\n",
            "  adding: results/83.txt (deflated 79%)\r\n",
            "  adding: results/84.txt (deflated 67%)\r\n",
            "  adding: results/85.txt (deflated 62%)\r\n",
            "  adding: results/86.txt (deflated 78%)\r\n",
            "  adding: results/87.txt (deflated 76%)\r\n",
            "  adding: results/88.txt (deflated 75%)\r\n",
            "  adding: results/89.txt (deflated 69%)\r\n",
            "  adding: results/9.txt (deflated 65%)\r\n",
            "  adding: results/90.txt (deflated 55%)\r\n",
            "  adding: results/91.txt (deflated 77%)\r\n",
            "  adding: results/92.txt (deflated 68%)\r\n",
            "  adding: results/93.txt (deflated 79%)\r\n",
            "  adding: results/94.txt (deflated 47%)\r\n",
            "  adding: results/95.txt (deflated 67%)\r\n",
            "  adding: results/96.txt (deflated 80%)\r\n",
            "  adding: results/97.txt (deflated 60%)\r\n",
            "  adding: results/98.txt (deflated 68%)\r\n",
            "  adding: results/99.txt (deflated 61%)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GKhG1wpTd68d",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "files.download(\"results.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1a_Zwbbifqkl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2730384b-8b80-4d26-f570-04fc8dee4cc0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531989833655,
          "user_tz": 240,
          "elapsed": 1491,
          "user": {
            "displayName": "Luming Hao",
            "photoUrl": "//lh5.googleusercontent.com/-2JGZDMtGqMo/AAAAAAAAAAI/AAAAAAAAAbM/npdYuGIdCN0/s50-c-k-no/photo.jpg",
            "userId": "107166296863023479912"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aquatic_config.json  aquatic_vocab.json    results.zip\r\n",
            "aquatic.csv\t     aquatic_weights.hdf5  textgenrnn_weights_saved.hdf5\r\n",
            "aquatic.json\t     results\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aSsX-jgWn16r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"results.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h-kIosjXn7Ud",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}